{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c5ef004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data.dataloader import DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "564cad18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "device\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc77332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff8810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANCER HISTOPATHOLOGY CNN CLASSIFIER\n",
      "\n",
      "[STEP 1] Running quick CNN connection test...\n",
      "QUICK TEST - Verifying CNN connections\n",
      "\n",
      "[TEST] Testing forward pass with dummy data...\n",
      "[TEST] Input shape: torch.Size([2, 3, 128, 128])\n",
      "\n",
      "[TEST] Layer-by-layer shape transformation:\n",
      "  Input: torch.Size([2, 3, 128, 128])\n",
      "  After conv1: torch.Size([2, 32, 128, 128])\n",
      "  After pool1: torch.Size([2, 32, 64, 64])\n",
      "  After conv2: torch.Size([2, 64, 64, 64])\n",
      "  After pool2: torch.Size([2, 64, 32, 32])\n",
      "  After conv3: torch.Size([2, 128, 32, 32])\n",
      "  After pool3: torch.Size([2, 128, 16, 16])\n",
      "  After conv4: torch.Size([2, 256, 16, 16])\n",
      "  After pool4: torch.Size([2, 256, 8, 8])\n",
      "  After flatten: torch.Size([2, 16384])\n",
      "\n",
      "[TEST] Full forward pass...\n",
      "[TEST] Output shape: torch.Size([2, 5])\n",
      "[TEST] ✓ CNN connections are correct!\n",
      "\n",
      "[TEST] Kernel sizes:\n",
      "  conv1: (3, 3)\n",
      "  conv2: (3, 3)\n",
      "  conv3: (3, 3)\n",
      "  conv4: (3, 3)\n",
      "\n",
      "[STEP 2] Starting actual training...\n",
      "NOTE: You should see output within 30-60 seconds!\n",
      "Traisn MODEL\n",
      "\n",
      "[SETUP] Device: cuda\n",
      "[SETUP] GPU: NVIDIA GeForce RTX 3080 Laptop GPU\n",
      "[SETUP] CUDA Memory: 8.6 GB\n",
      "\n",
      "[DATA] Loading dataset...\n",
      "✓ Root directory: lungcolon\n",
      "  colon_aca: 5000 images\n",
      "  colon_n: 5000 images\n",
      "  lung_aca: 5000 images\n",
      "  lung_n: 5000 images\n",
      "  lung_scc: 5000 images\n",
      "Total samples loaded: 25000\n",
      "\n",
      "[DATA] Dataset splits:\n",
      "  Training: 17500 samples\n",
      "  Validation: 3750 samples\n",
      "  Test: 3750 samples\n",
      "  Classes: ['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']\n",
      "MODEL ARCHITECTURE\n",
      "CancerCNN(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu4): ReLU()\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=16384, out_features=512, bias=True)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (relu_fc1): ReLU()\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (dropout2): Dropout(p=0.3, inplace=False)\n",
      "  (relu_fc2): ReLU()\n",
      "  (fc3): Linear(in_features=256, out_features=5, bias=True)\n",
      ")\n",
      "\n",
      "[MODEL] Total parameters: 8,911,109\n",
      "[MODEL] Trainable parameters: 8,911,109\n",
      "TRAINING STARTING NOW - WATCH FOR OUTPUT BELOW!\n",
      "\n",
      "You should see updates every 15-30 seconds...\n",
      "\n",
      "\n",
      "[EPOCH 1/20] Starting...\n",
      "[BATCH 1] Loss: 1.6039, Acc: 31.2%, Time: 0.5s\n",
      "[INFO] First batch completed! Training continues...\n",
      "[BATCH 10] Avg Loss: 2.0810, Current Acc: 49.1%\n",
      "[BATCH 20] Avg Loss: 1.7558, Current Acc: 54.5%\n",
      "[BATCH 30] Avg Loss: 1.5195, Current Acc: 57.8%\n",
      "[BATCH 40] Avg Loss: 1.4005, Current Acc: 58.2%\n",
      "[BATCH 50] Avg Loss: 1.2767, Current Acc: 59.8%\n",
      "[BATCH 60] Avg Loss: 1.1729, Current Acc: 61.1%\n",
      "[BATCH 70] Avg Loss: 1.1074, Current Acc: 61.8%\n",
      "[BATCH 80] Avg Loss: 1.0533, Current Acc: 62.4%\n",
      "[BATCH 90] Avg Loss: 1.0032, Current Acc: 63.2%\n",
      "[BATCH 100] Avg Loss: 0.9581, Current Acc: 64.1%\n",
      "[BATCH 110] Avg Loss: 0.9179, Current Acc: 65.3%\n",
      "[BATCH 120] Avg Loss: 0.8882, Current Acc: 66.3%\n",
      "[BATCH 130] Avg Loss: 0.8590, Current Acc: 67.0%\n",
      "[BATCH 140] Avg Loss: 0.8284, Current Acc: 68.1%\n",
      "[BATCH 150] Avg Loss: 0.8191, Current Acc: 68.7%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "# 1. BASE CNN MODEL \n",
    "class CancerCNN(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(CancerCNN, self).__init__()\n",
    "        \n",
    "        # RULE: Each conv layer maintains spatial size with padding=1\n",
    "        # RULE: MaxPool2d(kernel_size=2, stride=2) halves the spatial dimensions\n",
    "        \n",
    "        # Input: 3 channels (RGB)\n",
    "        \n",
    "        # Conv Block 1\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # 128x128 -> 128x128 (padding keeps size)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)  # 128x128 -> 64x64\n",
    "        \n",
    "        # Conv Block 2\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # 64x64 -> 64x64\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)  # 64x64 -> 32x32\n",
    "        \n",
    "        # Conv Block 3\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 32x32 -> 32x32\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)  # 32x32 -> 16x16\n",
    "        \n",
    "        # Conv Block 4\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)  # 16x16 -> 16x16\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)  # 16x16 -> 8x8\n",
    "        \n",
    "        #256 channels * 8 * 8 = 16384\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(256 * 8 * 8, 512)  # 16384 -> 512\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.relu_fc1 = nn.ReLU()\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.relu_fc2 = nn.ReLU()\n",
    "        \n",
    "        self.fc3 = nn.Linear(256, num_classes)  # Final output\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Conv Block 1\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        # Conv Block 2\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        # Conv Block 3\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "        \n",
    "        # Conv Block 4\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.pool4(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # FC Layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu_fc1(x)\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.relu_fc2(x)\n",
    "        \n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# 2. DATASET CLASS\n",
    "\n",
    "class CancerDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = ['colon_aca', 'colon_n', 'lung_aca', 'lung_n', 'lung_scc']\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        self.samples = []\n",
    "        \n",
    "        print(f\"✓ Root directory: {root_dir}\")\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if os.path.exists(class_dir):\n",
    "                images = [f for f in os.listdir(class_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff'))]\n",
    "                for img_name in images[:5000]:  # Used to check if loading works on smaller samples\n",
    "                    img_path = os.path.join(class_dir, img_name)\n",
    "                    self.samples.append((img_path, self.class_to_idx[class_name]))\n",
    "                print(f\"  {class_name}: {len(images)} images\")\n",
    "        \n",
    "        print(f\"Total samples loaded: {len(self.samples)}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "\n",
    "# 3. TRAINING FUNCTION \n",
    "def train_with_immediate_output():\n",
    "      \n",
    "    print(\"Traisn MODEL\")\n",
    "     \n",
    "    \n",
    "    # Setup\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"\\n[SETUP] Device: {device}\")\n",
    "    if device.type == 'cuda':\n",
    "        print(f\"[SETUP] GPU: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"[SETUP] CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    \n",
    "    # Define transforms\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  # Fixed size\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "    \n",
    "    # Load dataset\n",
    "    print(\"\\n[DATA] Loading dataset...\")\n",
    "    data_dir = \"lungcolon\"\n",
    "    \n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"ERROR: Dataset not found at '{data_dir}'\")\n",
    "\n",
    "        return\n",
    "    \n",
    "    # Create dataset\n",
    "    dataset = CancerDataset(root_dir=data_dir, transform=transform)\n",
    "    \n",
    "    # Split dataset (70% train, 15% val, 15% test)\n",
    "    train_size = int(0.7 * len(dataset))\n",
    "    val_size = int(0.15 * len(dataset))\n",
    "    test_size = len(dataset) - train_size - val_size\n",
    "    \n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset, [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n[DATA] Dataset splits:\")\n",
    "    print(f\"  Training: {len(train_dataset)} samples\")\n",
    "    print(f\"  Validation: {len(val_dataset)} samples\")\n",
    "    print(f\"  Test: {len(test_dataset)} samples\")\n",
    "    print(f\"  Classes: {dataset.classes}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)  # num_workers=0 for immediate output\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # Create model\n",
    "    model = CancerCNN(num_classes=len(dataset.classes)).to(device)\n",
    "    \n",
    "      \n",
    "    print(\"MODEL ARCHITECTURE\")\n",
    "     \n",
    "    print(model)\n",
    "    \n",
    "    # Calculate parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"\\n[MODEL] Total parameters: {total_params:,}\")\n",
    "    print(f\"[MODEL] Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    # Training setup\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "      \n",
    "    print(\"TRAINING\")\n",
    "     \n",
    "    \n",
    "    \n",
    "    # Training loop\n",
    "    num_epochs = 20  # Start with 3 epochs for quick results IF CPU it will take hors \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        print(f\"\\n[EPOCH {epoch+1}/{num_epochs}] Starting...\")\n",
    "    \n",
    "        \n",
    "        # Training batches\n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            batch_start_time = time.time()\n",
    "            \n",
    "            # Move to device\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            batch_total = labels.size(0)\n",
    "            batch_correct = (predicted == labels).sum().item()\n",
    "            \n",
    "            # Update statistics\n",
    "            running_loss += loss.item()\n",
    "            total += batch_total\n",
    "            correct += batch_correct\n",
    "            \n",
    "            # Print immediate progress\n",
    "            batch_time = time.time() - batch_start_time\n",
    "            \n",
    "            if batch_idx == 0:\n",
    "                print(f\"[BATCH 1] Loss: {loss.item():.4f}, Acc: {100*batch_correct/batch_total:.1f}%, Time: {batch_time:.1f}s\")\n",
    "                print(f\"[INFO] First batch completed! Training continues...\")\n",
    "            elif (batch_idx + 1) % 10 == 0:  # Print every 10 batches\n",
    "                avg_loss = running_loss / (batch_idx + 1)\n",
    "                current_acc = 100 * correct / total\n",
    "                print(f\"[BATCH {batch_idx+1}] Avg Loss: {avg_loss:.4f}, Current Acc: {current_acc:.1f}%\")\n",
    "        \n",
    "        # Epoch statistics\n",
    "        epoch_time = time.time() - epoch_start_time\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_acc = 100 * correct / total\n",
    "        \n",
    "        print(f\"\\n[EPOCH {epoch+1} SUMMARY]\")\n",
    "        print(f\"  Loss: {epoch_loss:.4f}\")\n",
    "        print(f\"  Accuracy: {epoch_acc:.2f}%\")\n",
    "        print(f\"  Time: {epoch_time:.1f} seconds\")\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"[VALIDATION] Loss: {avg_val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "        \n",
    "        \n",
    "        model.train()  # Set back to training mode\n",
    "    \n",
    "    # Save model\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'epochs': num_epochs,\n",
    "        'loss': epoch_loss,\n",
    "        'accuracy': epoch_acc,\n",
    "        'classes': dataset.classes\n",
    "    }, 'cancer_cnn_model.pth')\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING COMPLETE!\")\n",
    "     \n",
    "    print(f\"Model saved as 'cancer_cnn_model.pth'\")\n",
    "    print(f\"Final Training Accuracy: {epoch_acc:.2f}%\")\n",
    "    print(f\"Final Validation Accuracy: {val_acc:.2f}%\")\n",
    "    print(f\"Total training time: {time.time() - start_time:.1f} seconds\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 4.  TEST FUNCTION\n",
    "\n",
    "def quick_test():\n",
    "    \"\"\"Quick test to verify everything works before full training\"\"\"\n",
    "      \n",
    "    print(\"QUICK TEST - Verifying CNN connections\")\n",
    "     \n",
    "    \n",
    "    # Create a simple model\n",
    "    model = CancerCNN(num_classes=5)\n",
    "    \n",
    "    # Test forward pass\n",
    "    print(\"\\n[TEST] Testing forward pass with dummy data...\")\n",
    "    dummy_input = torch.randn(2, 3, 128, 128)  # Batch of 2, 3 channels, 128x128\n",
    "    \n",
    "    print(f\"[TEST] Input shape: {dummy_input.shape}\")\n",
    "    \n",
    "    # Test each layer\n",
    "    x = dummy_input\n",
    "    print(f\"\\n[TEST] Layer-by-layer shape transformation:\")\n",
    "    print(f\"  Input: {x.shape}\")\n",
    "    \n",
    "    # Conv Block 1\n",
    "    x = model.conv1(x)\n",
    "    print(f\"  After conv1: {x.shape}\")\n",
    "    x = model.bn1(x)\n",
    "    x = model.relu1(x)\n",
    "    x = model.pool1(x)\n",
    "    print(f\"  After pool1: {x.shape}\")\n",
    "    \n",
    "    # Conv Block 2\n",
    "    x = model.conv2(x)\n",
    "    print(f\"  After conv2: {x.shape}\")\n",
    "    x = model.bn2(x)\n",
    "    x = model.relu2(x)\n",
    "    x = model.pool2(x)\n",
    "    print(f\"  After pool2: {x.shape}\")\n",
    "    \n",
    "    # Conv Block 3\n",
    "    x = model.conv3(x)\n",
    "    print(f\"  After conv3: {x.shape}\")\n",
    "    x = model.bn3(x)\n",
    "    x = model.relu3(x)\n",
    "    x = model.pool3(x)\n",
    "    print(f\"  After pool3: {x.shape}\")\n",
    "    \n",
    "    # Conv Block 4\n",
    "    x = model.conv4(x)\n",
    "    print(f\"  After conv4: {x.shape}\")\n",
    "    x = model.bn4(x)\n",
    "    x = model.relu4(x)\n",
    "    x = model.pool4(x)\n",
    "    print(f\"  After pool4: {x.shape}\")\n",
    "    \n",
    "    # Flatten\n",
    "    x = model.flatten(x)\n",
    "    print(f\"  After flatten: {x.shape}\")\n",
    "    \n",
    "    # Full forward pass\n",
    "    print(f\"\\n[TEST] Full forward pass...\")\n",
    "    output = model(dummy_input)\n",
    "    print(f\"[TEST] Output shape: {output.shape}\")\n",
    "    print(f\"[TEST] ✓ CNN connections are correct!\")\n",
    "    \n",
    "    # Check kernel sizes\n",
    "    print(f\"\\n[TEST] Kernel sizes:\")\n",
    "    print(f\"  conv1: {model.conv1.kernel_size}\")\n",
    "    print(f\"  conv2: {model.conv2.kernel_size}\")\n",
    "    print(f\"  conv3: {model.conv3.kernel_size}\")\n",
    "    print(f\"  conv4: {model.conv4.kernel_size}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "\n",
    "# 5. MAIN \n",
    "if __name__ == \"__main__\":\n",
    "    start_time = time.time()\n",
    "    \n",
    "      \n",
    "    print(\"CANCER HISTOPATHOLOGY CNN CLASSIFIER\")\n",
    "     \n",
    "    \n",
    "    # Step 1: Quick test\n",
    "    print(\"\\n Running quick CNN connection test...\")\n",
    "    quick_test()\n",
    "    \n",
    "    # Step 2: Training\n",
    "    print(\"\\n Starting actual training...\")\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        model = train_with_immediate_output()\n",
    "        \n",
    "          \n",
    "        \n",
    "    except Exception as e:\n",
    "       print (f\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5342fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed94959c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
